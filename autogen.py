#!/usr/bin/env python3

import argparse
import git
import os
import io
import shutil
import re
import csv

from glob import glob

DEFAULT_ARR_SIZE=8
C_HEADERS=['<stdio.h>', '<string.h>', '<stdlib.h>', '<stdint.h>']
BOILERPLATE_HEADERS=['utils.h', 'concrete.h', 'symbolic.h']
KLEE_HEADERS=['klee/klee.h']
HEADER_COMMENT="""/* This file was automatically generated by autogen.py */\n\n"""
TD_PREFIX="autotd"

def create_outputstream():
    f = io.StringIO()
    f.write(HEADER_COMMENT)
    return f

def is_valid_outputstream(outputstream):
    if type(outputstream) is not io.StringIO:
        sys.stderr.write("Expected type: io.StringIO\nActual type: {}".format(type(outputstream)))
        sys.exit(1)

def read_csv(csv_file):
    """Reads rows of CSV file. Returns a list of tuples."""
    results = []
    with open(csv_file, newline='') as f:
        reader = csv.reader(csv_file, delimiter=':')
        for row in reader:
            results.append(row)
    return results

def write_with_tabs(outputstream, output_str, tabs=0):
    is_valid_outputstream(outputstream)
    for i in range(tabs):
        output_tab(outputstream)
    outputstream.write(output_str)

def output_newline(outputstream):
    outputstream.write("\n")

def output_tab(outputstream):
    outputstream.write("\t")

def output_boilerplate_headers(outputstream):
    for header in BOILERPLATE_HEADERS:
        output_str = "#include \"{}\"\n".format(header)
        outputstream.write(output_str)

def output_stdc_headers(outputstream):
    for header in C_HEADERS:
        output_str = "#include {}\n".format(header)
        outputstream.write(output_str)

def output_lib_headers(repo_dir, outputstream):
    # Find all 'include' dirs and add the absolute paths of all header files found within them
    #   find repo_dir -type d -name '*include' -print > include_dirs
    #   for each dir in include_dirs: for each root, subdir, files in os.walk(dir): if 
    include_files = []

    for root, _, _ in os.walk(repo_dir):
        for y in glob(os.path.join(root, '*.h')):
            include_files.append(y)

    for f in include_files:
        output_str = "#include \"{}\"\n".format(f)
        outputstream.write(output_str)

class TDContext:
    _id = 0

    def __init__(self, funcname, functype, params):
        TDContext._id += 1

        self.id       = TDContext._id # Used to number output files (i.e: test drivers)
        self.funcname = funcname
        self.functype = functype
        self.params   = params
        #self.params   = self.split_by(params, ',') # So input 'params' should be single string with commas separating actual function parameters

    def split_by(self, string, delim):
        return [x.strip() for x in string.split(delim)]

    def get_vars_from_params(self):
        """Creates list of 'Variable' objects from 'self''s list of 'params'"""
        variables = []
        pattern = r"([a-zA-Z_][a-zA-Z0-9_]*)(?:\s*\*?\*?\s*)([a-zA-Z_][a-zA-Z0-9_]*)" # TODO: Potential false positive for x*y or similar
        for param in self.params:
            x = re.match(pattern, params)


    def dump_to_cfile(self, outputstream):
        filename = TD_PREFIX + '{}.c'.format(self.id)
        with open(filename, 'w') as f:
            outputstream.seek(0)
            shutil.copyfileobj(outputstream, f)

class Variable:
    vars_to_free = []

    def __init__(self, _id, name, _type, isPtr=False, arrSize=0):
        self.id      = _id
        self.name    = name + str(_id)
        self.type   = _type
        self.isPtr   = isPtr
        self.arrSize = arrSize

    def get_name(self):
        return self.name

    def get_id(self):
        return self.id

    def get_type(self):
        return self.type

    def is_ptr():
        return self.isPtr

    def get_arr_size():
        return self.arrSize

    def output_mk_var(self, outputstream):
        # Check outputstream is valid
        # Procedure for initialising variable:
        #   [self._type] [self.name] = malloc(sizeof([self._type]))
        #   Push [self.name] onto vars_to_free
        #   Output check testing whether malloc was successful (remember to free vars)
        #   Output klee_make_symbolic (should call Klee.output_symbolic(self, outputstream))
        is_valid_outputstream(outputstream)

        if self.isPtr:
            output_str = "{} *{} = malloc(sizeof(*{}));\n".format(self.type, self.name, self.name)
            outputstream.write(output_str)
            Variable.vars_to_free.append(self)
            output_str = "if (!{})\n\tmalloc_fail(-1);\n".format(self.name)
            outputstream.write(output_str)
        else:
            output_str = "{} {};\n".format(self.type, self.name)
            outputstream.write(output_str)
        Klee.output_symbolic(self, outputstream)
        return

    def output_free_vars(outputstream):
        # Output free calls for variables in 'vars_to_free', from last element to first
        is_valid_outputstream(outputstream)
        return

class Klee:

    @staticmethod
    def output_headers(outputstream):
        is_valid_outputstream(outputstream)
        for header in KLEE_HEADERS:
            output_str = "#include \"{}\"\n".format(header)
            outputstream.write(output_str)

    @staticmethod
    def output_init(outputstream):
        is_valid_outputstream(outputstream)
        output_str = "int main()\n{\n"
        outputstream.write(output_str)

    @staticmethod
    def output_footer(outputstream):
        is_valid_outputstream(outputstream)
        output_tab(outputstream)
        output_str = "return 0;\n}"
        outputstream.write(output_str)
        return

    @staticmethod
    def output_symbolic(var, outputstream):
        is_valid_outputstream(outputstream)
        output_tab(outputstream)
        if var.is_ptr():
            output_str = "klee_make_symbolic({}, sizeof {}, \"{}\");\n".format(var.get_name(), var.get_name(), var.get_name())
            outputstream.write(output_str)
        else:
            output_str = "klee_make_symbolic(&{}, sizeof {}, \"{}\");\n".format(var.get_name(), var.get_name(), var.get_name())
            outputstream.write(output_str)

    @staticmethod
    def output_assume(var1, var2, outputstream):
        is_valid_outputstream(outputstream)
        if var.is_ptr():
            _str1 = "int i;\n"
            _str2 = "for (i=0; i < {}; i++)\n"
            _str3 = "{\n"
            _str4 = "klee_assume({}[i] == {}[i]);\n".format(var1.get_name(), var2.get_name())
            _str5 = "}\n\n"
            write_with_tabs(outputstream, _str1, 1)
            write_with_tabs(outputstream, _str2, 1)
            write_with_tabs(outputstream, _str3, 1)
            write_with_tabs(outputstream, _str4, 2)
            write_with_tabs(outputstream, _str5, 1)
        else:
            _str1 = "klee_assume({} == {});\n\n".format(var1.get_name(), var2.get_name())
            write_with_tabs(outputstream, _str1, 1)
                
    @staticmethod
    def output_assert(var1, var2, outputstream):
        is_valid_outputstream(outputstream)
        return

def get_arguments():
    """Grab user supplied arguments"""
    parser = argparse.ArgumentParser()
    parser.add_argument("-i", "--input-file", required=True, help="Input CSV file", type=str)
    parser.add_argument("-r", "--repository", required=True, help="Path to git repository", type=str)
    parser.add_argument("--sortby", required=False, choices=['lines-changed', 'lines-added', 
                        'lines-removed', 'functions-changed', 'functions-added', 'functions-removed'],
                        default='functions-changed',
                        help=
                        """
                        Optional comparator to sort data from CSV file. Use with the
                        '--depth N' so that test drivers are generated for the top N
                        inputs as specified by the comparator.
                        """)
    parser.add_argument("-d", "--depth", required=False, default=10, type=int, help="Number of test drivers to generate (default 10)")
    args = parser.parse_args()

    # Validate arguments
    is_valid_csv(args.input_file)
    is_valid_repo(args.repository)
    return args

def is_valid_csv(input_file):
    if not input_file.endswith('.csv'):
        sys.stderr.write("The file {} is not a valid CSV file".format(input_file))
        sys.exit(1)

def is_valid_repo(path):
    """Ensure that the input file exists"""
    if not os.path.exists(os.path.join(path, '.git')):
        sys.stderr.write("The path '{}' does not point to a valid Git Repository".format(path))
        sys.exit(1)

if __name__ == "__main__":
    arguments = get_arguments()
    #TODO: Get list of records of form: (funcname, functype, list of params (incl. types))
    # The records retrieved should be indexed by pairs of revisions: (rev1, rev2)
    # So we need to extract this info from the verbose CSV file, not the one given as input.
    td_context = TDContext(None, None, None)
    outputstream = create_outputstream()

    output_stdc_headers(outputstream)
    output_lib_headers(arguments.repository, outputstream)
    output_boilerplate_headers(outputstream)
    Klee.output_headers(outputstream)

    csv_rows = read_csv(arguments.input_file)
    #functions_added = csv_rows[5]
    #functions_removed = csv_rows[6]
    #functions_modified = csv_rows[7]

    #TODO: We'll just use 'functions_modified for now'. Expand functionality later.


    td_context.dump_to_cfile(outputstream)
